# 2412.06264v1

## 1. 引言

### 1.1 文档的主要目标：
1. 作为全面且自成体系的Flow Matching参考资料：文档详细阐述了Flow Matching的设计选择和研究社区开发的众多扩展。例如，在数学基础上，深入讲解了概率路径、流与速度场的等价性以及连续性方程等核心概念；在设计选择上，介绍了条件Flow Matching（CFM）、仿射条件流等多种形式，还探讨了不同的概率路径构建方式；同时，涵盖了非欧几里得Flow Matching、离散Flow Matching等扩展内容，展现了该框架在不同场景下的应用可能性。

2. 帮助研究者快速采用和构建Flow Matching相关应用：文档提供了实用的资源和示例。不仅包含PyTorch代码库（flow_matching library，https://github.com/facebookresearch/flow_matching），还给出了多个具体的代码示例，如独立的Flow Matching实现代码、使用中点求解器计算目标样本的代码等。这些代码和工具使得研究者能够快速上手，将Flow Matching应用到自己的研究或项目中。

### 1.2 流匹配的发展历程

- **早期基础（2018年）**：Chen等人和Grathwohl等人于2018年将流模型以连续归一化流（CNFs）的形式引入机器学习社区 ，最初通过最大化训练样本的似然来训练流模型，训练过程需模拟ODE及其微分，存在计算负担。
- **方法提出（2022 - 2023年）**：2022 - 2023年，Yaron Lipman等人提出流匹配（Flow Matching）方法（论文《Flow Matching for Generative Modeling》） ，这是一种建立在连续正常化流（CNF）基础上的新型生成建模范式，通过回归概率流的速度场来训练模型，避免了传统CNF每步都进行数值积分ODE的问题，开启了流匹配的发展。同期，Albergo和Vanden - Eijnden、Liu等人也分别对相关研究做出贡献。
- **应用拓展（2024年及以后）** ：
  - 离散流匹配（Discrete Flow Matching）（Campbell 等人，2024；Gat 等人，2024）开发了一种适用于离散状态空间上连续时间马尔可夫过程（也称为连续时间马尔可夫链，CTMC）的流匹配算法
  - 黎曼流匹配（Riemannian Flow Matching）（Chen 和 Lipman，2024）将流匹配扩展到黎曼流形\(S = M\)上的流，如今已成为化学领域中多种机器学习应用（如蛋白质折叠）的最先进模型（Yim 等人，2023；Bose 等人，2023）。
  - 生成器匹配（Generator Matching）（Holderrieth 等人，2024）表明，流匹配框架适用于任何模态和一般的连续时间马尔可夫过程（CTMPs）

### 1.3 文档的目录结构:
第2节提供了一个独立完整的“速查表”，帮助读者理解并在PyTorch中实现基础的流匹配（vanilla Flow Matching）。第3节对连续状态空间下的流模型进行了严谨的阐述，流模型可以说是所有连续时间马尔可夫过程（CTMPs）中最简单的一种。第4节介绍了\(\mathbb{R}^{d}\)空间中的流匹配框架及其各种设计选择和扩展。我们将展示，通过考虑显著更简单的条件设定，能够构建流模型，这为流模型的设计提供了极大的灵活性，例如可以轻松扩展到第5节所描述的黎曼几何。第6节介绍了连续时间马尔可夫链（CTMCs）及其作为离散状态空间上生成模型的应用。第7节则探讨了流匹配向CTMC过程的扩展。第8节介绍了如何将连续时间马尔可夫过程（CTMPs）用作任意状态空间的生成模型。第9节描述了生成器匹配（GM）——这是一个适用于任意模态的生成建模范式，它给出了一种可扩展的连续时间马尔可夫过程训练方法。生成器匹配还将前面各节中的所有模型统一到一个通用框架中。最后，由于去噪扩散模型的广泛应用，我们在第10节中将其作为流匹配家族模型的一个具体实例进行讨论。

## 2. 快速入门与核心概念
流匹配训练速度场(velocity filed, 即向量场),通过概率路径\((p_t)_{0 \le t\le 1}\),将源分布\(p_0 = p\)转移到目标分布\(p_1 = 1\)

在2022年的论文笔记中已经有核心概念的定义,不再对每个概念的定义做详细解释,仅列出主要关系式.本文主要使用速度场的说法替代2022年原论文的向量场.

速度场通过ODE决定流:
\[\frac{d}{d t} \psi_{t}(x)=u_{t}\left(\psi_{t}(x)\right),\]

流(由速度场决定)生成概率路径
\[X_{t}:=\psi_{t}\left(X_{0}\right) \sim p_{t} for X_{0} \sim p_{0} . \tag{2.1}\]

训练的两个步骤:1. 设计概率路径  2.通过神经网络训练生成概率路径的速度场

概率路径满足以下公式:

\[p_{t}(x)=\int p_{t | 1}\left(x | x_{1}\right) q\left(x_{1}\right) d x_{1}, where p_{t | 1}\left(x | x_{1}\right)=\mathcal{N}\left(x | t x_{1},(1-t)^{2} I\right) . \tag{2.2}\]

以上概率路径称为条件最优传输或者线性路径.用以上概率路径可以通过采样\(X_{0} ~ p\)和\(X_{1} ~ q\)获得随机变\(X_{t} ~ p_{t}\):
\[X_{t}=t X_{1}+(1-t) X_{0} \sim p_{t} . \tag{2.3}\]

流匹配损失函数:
\[\mathcal{L}_{FM}(\theta)=\mathbb{E}_{t, X_{t}}\left\| u_{t}^{\theta}\left(X_{t}\right)-u_{t}\left(X_{t}\right)\right\| ^{2} , where t \sim \mathcal{U}[0,1] and X_{t} \sim p_{t} . \tag{2.4}\]

实践中\(u_t\)难以得到, 为了解决这个问题,使用条件随机变量:
\[X_{t | 1}=t x_{1}+(1-t) X_{0} \sim p_{t | 1}\left(\cdot | x_{1}\right)=\mathcal{N}\left(\cdot | t x_{1},(1-t)^{2} I\right) .\tag{2.5}\]

对这个条件随机变量(相当于一个流)解ode,得到条件速度场:
\[u_{t}\left(x | x_{1}\right)=\frac{x_{1}-x}{1-t}, \tag{2.6}\]

条件速度场可以生成条件概率路径.用这个简单的条件速度场,可以得到容易求解的条件流匹配损失函数:
\[\mathcal{L}_{CFM}(\theta)=\mathbb{E}_{t, X_{t}, X_{1}}\left\| u_{t}^{\theta}\left(X_{t}\right)-u_{t}\left(X_{t} | X_{1}\right)\right\| ^{2} , \\where t \sim U[0,1], X_{0} \sim p, X_{1} \sim q, \tag{2.7}\]

流匹配损失函数和条件流匹配损失函数有相同梯度:
\[\nabla_{\theta} \mathcal{L}_{FM}(\theta)=\nabla_{\theta} \mathcal{L}_{CFM}(\theta) .\tag{2.8}\]

将(2.6)代入(2.7),得到最简单的流匹配实现:
\[\mathcal{L}_{CFM}^{OT,Gauss}(\theta)=\mathbb{E}_{t, X_{0}, X_{1}}\left\| u_{t}^{\theta}\left(X_{t}\right)-\left(X_{1}-X_{0}\right)\right\| ^{2} , \\where t \sim U[0,1], X_{0} \sim \mathcal{N}(0, I), X_{1} \sim q . \tag{2.9}\]

# 3. 流模型
本节介绍流（flows）这一数学对象，它是最简单形式的流匹配（Flow Matching）的核心驱动力。本文后续部分将讨论比流更一般的马尔可夫过程，进而引出更复杂的生成学习范式，为流匹配框架带来更多设计选择。我们从流开始介绍有三个原因：首先，流可以说是所有连续时间马尔可夫过程（CTMPs）中最简单的一种——它具有确定性，并且可以通过速度场进行简洁的参数化，只要源分布\(p\)和目标分布\(q\)都有密度，流模型就能将任意源分布\(p\)转换为任意目标分布\(q\)。其次，与扩散过程中较难模拟的随机微分方程（SDEs）相比，通过近似求解常微分方程（ODEs），流可以实现高效采样。第三，流的确定性本质使得模型似然估计无偏，而更一般的随机过程则需要依赖下界进行估计。为了理解流，我们必须首先回顾概率和微分方程理论中的一些背景知识，接下来就进行这部分内容的介绍。

## 3.1 随机向量
关于密度函数,d维各向同性高斯分布,数学期望的定义.

## 3.2 条件密度和条件期望
关于联合概率密度,边缘密度函数,条件概率密度,条件期望的定义

## 3.3 Diffeomorphismsandpush-forwardmaps 微分同胚和推前映射
我们用\(C^{r}(\mathbb{R}^{m}, \mathbb{R}^{n})\)表示具有r阶连续偏导数的函数\(f: \mathbb{R}^{m} \to \mathbb{R}^{n}\)的集合，其中r阶偏导数为
\[\frac{\partial^{r} f^{k}}{\partial x^{i_{1}} \cdots \partial x^{i_{r}}}, k \in[n], i_{j} \in[m],\tag{3.13}\]

其中\([n] := \{1, 2, \ldots, n\}\)。为使符号简洁，我们还定义\(C^{r}(\mathbb{R}^{n}) := C^{r}(\mathbb{R}^{m}, \mathbb{R})\)，例如，\(C^{1}(\mathbb{R}^{m})\)表示连续可微的标量函数。一类重要的函数是 **\(C^{r}\)微分同胚**；它们是可逆函数\(\psi \in C^{r}(\mathbb{R}^{n}, \mathbb{R}^{n})\)，且其逆函数\(\psi^{-1} \in C^{r}(\mathbb{R}^{n}, \mathbb{R}^{n})\)。

那么，给定一个具有密度\(p_X\)的随机变量\(X \sim p_X\)，我们考虑随机变量\(Y = \psi(X)\)，其中\(\psi: \mathbb{R}^d \to \mathbb{R}^d\)是一个\(C^1\)微分同胚。\(Y\)的概率密度函数记为\(p_Y\)，也称为\(p_X\)的推前（push-forward）。通过变量替换，可以计算\(p_Y\)：

\[
\mathbb{E}[f(Y)] = \mathbb{E}[f(\psi(X))] = \int f(\psi(x)) p_X(x) dx = \int f(y) p_X\left(\psi^{-1}(y)\right) \left| \det \partial_y \psi^{-1}(y) \right| dy
\]

其中，第三个等式是由于变量替换\(x = \psi^{-1}(y)\)。\(\partial_y \phi(y)\)表示雅克比矩阵（一阶偏导数矩阵），即：

\[
\left[ \partial_y \phi(y) \right]_{i,j} = \frac{\partial \phi^i}{\partial x^j}, \quad i, j \in [d]
\]

而\(\det A\)表示方阵\(A \in \mathbb{R}^{d \times d}\)的行列式。因此，我们得出\(p_Y\)的概率密度函数为：

\[
p_Y(y) = p_X\left( \psi^{-1}(y) \right) \left| \det \partial_y \psi^{-1}(y) \right| \tag{3.14}
\]

我们将用符号\(\sharp\)表示推前算子，即
\[
\left[\psi_{\sharp} p_{X}\right](y) := p_{X}\left(\psi^{-1}(y)\right)\left| \det \partial_{y} \psi^{-1}(y) \right| . \tag{3.15}
\]

## 3.4 作为生成式模型的流
如第2节所述，生成建模的目标是将源分布\(p\)中的样本\(X_{0}=x_{0}\)转换为目标分布\(q\)中的样本\(X_{1}=x_{1}\)。在本节中，我们开始构建通过流映射\(\psi_{t}\)解决这一问题所需的工具。更正式地说，\(C^{r}\)流是一个依赖时间的映射\(\psi:[0,1] ×\mathbb{R}^{d} \to \mathbb{R}^{d}\)，即\(\psi:(t, x) \mapsto \psi_{t}(x)\)。这种流也是一个\(C^{r}([0,1] ×\mathbb{R}^{d}, \mathbb{R}^{d})\)函数，使得对于所有\(t \in[0,1]\)，函数\(\psi_{t}(x)\)是关于\(x\)的\(C^{r}\)微分同胚。流模型是一个连续时间马尔可夫过程\((X_{t})_{0 ≤t ≤1}\)，它通过将流\(\psi_{t}\)应用于随机变量\(X_{0}\)来定义：
\[X_{t}=\psi_{t}\left(X_{0}\right),\quad t \in[0,1],\quad 其中\ X_{0} \sim p . \tag{3.16}\]

参见图5对流模型的说明。要理解为何\(X_t\)是马尔可夫过程，请注意，对于任意满足\(0 \leq t < s \leq 1\)的时间点，有
\[X_s = \psi_s(X_0) = \psi_s\left(\psi_t^{-1}\left(\psi_t(X_0)\right)\right) = \psi_{s|t}(X_t),\tag{3.17}\]
其中最后一个等式是通过式（3.16）令\(X_t = \psi_t(X_0)\)，并定义\(\psi_{s|t} := \psi_s \circ \psi_t^{-1}\)（这也是一个微分同胚）得到的。\(X_s = \psi_{s|t}(X_t)\)表明，\(X_t\)之后的状态仅依赖于\(X_t\)，因此\(X_t\)是马尔可夫过程。事实上，对于流模型而言，这种依赖关系是确定性的。

总之，生成式流模型的目标是找到一个流\(\psi_{t}\)，使得
\[X_{1}=\psi_{1}\left(X_{0}\right) \sim q . \tag{3.18}\]

### 3.4.1 流和速度场的等价性
一个\(C^{r}\)流\(\psi\)可以通过一个\(C^{r}([0,1] ×\mathbb{R}^{d}, \mathbb{R}^{d})\)速度场\(u:[0,1] ×\mathbb{R}^{d} \to \mathbb{R}^{d}\)（该速度场实现了\(u:(t, x) \mapsto u_{t}(x)\)），并借助以下常微分方程（ODE）来定义：
\[ \frac {d}{dt}\psi _{t}(x)=u_{t}(\psi _{t}(x)) \tag{3.19a}\]

\[\psi_{0}(x)=x \tag{3.19b}\]

定理1（流的局部存在性与唯一性）：若\(u\)是\(C^{r}([0,1] ×\mathbb{R}^{d}, \mathbb{R}^{d})\)函数，且\(r ≥1\)（特别是局部 Lipschitz 连续的），则方程（3.19）存在唯一解，该解是定义在开集\(\Omega\)上的\(C^{r}(\Omega, \mathbb{R}^{d})\)微分同胚\(\psi_{t}(x)\)，其中\(\Omega\)是\(\{0\} ×\mathbb{R}^{d}\)的超集。

定理1说明速度场可以决定一个流。下面的公式（3.20）说明用流可以解出唯一的速度场。至此，流和速度场的等价性证明完毕。

\[u_{t}(x)=\dot{\psi}_{t}\left(\psi_{t}^{-1}(x)\right), \tag{3.20}\]
其中 \(\dot{\psi}_{t}:=\frac{d}{d t} \psi_{t}\) .

### 3.4.2 从源样本计算目标样本
计算目标样本\(X_{1}\)——或者更一般地说，计算任何样本\(x_{t}\)——需要从某个初始条件\(X_{0}=x_{0}\)出发，近似求解方程（3.19）中的常微分方程。常微分方程的数值解法是数值分析中一个经典且研究充分的课题，存在大量有效的方法（Iserles，2009）。其中最简单的方法之一是欧拉方法，它采用如下更新规则：
\[X_{t+h}=X_{t}+h u_{t}\left(X_{t}\right) \tag{3.21}\]

其中\(h = n^{-1}>0\)是步长超参数，且\(n \in \mathbb{N}\)。为了从目标分布中抽取样本\(X_{1}\)，需从某个\(X_{0} \sim p\)出发应用欧拉方法，生成序列\(X_{h}, X_{2h}, \ldots, X_{1}\)。欧拉方法与\(x_{t}\)的一阶泰勒展开一致：
\[X_{t+h}=X_{t}+h \dot{X}_{t}+o(h)=X_{t}+h u_{t}\left(X_{t}\right)+o(h),\]
其中\(o(h)\)表示增长速度慢于\(h\)的函数，即当\(h \to 0\)时，\(o(h)/h \to 0\)。因此，欧拉方法每步积累\(o(h)\)的误差，且可以证明经过\(n = 1/h\)步后积累的误差为\(o(1)\)。所以，当我们考虑更小的步长\(h \to 0\)时，欧拉方法的误差会消失。欧拉方法只是众多常微分方程求解器中的一个例子。另一种选择是二阶中点法，它在实际应用中通常优于欧拉方法。

## 3.5 概率路径和连续性方程
概率路径: \((p_{t})_{0 ≤t ≤1}\)

一个重要的概率路径是\(X_{t}=\psi_{t}(X_{0})\)的边缘密度函数 : 
\[X_{t} \sim p_{t} . \tag{3.22}\]

对于每个时间\(t \in[0,1]\)，这些边际概率密度函数可通过式（3.15）中的前推公式得到，即
\[p_{t}(x)=\left[\psi_{t \#} p\right](x) \tag{3.23}\]

给定某个任意的概率路径\(p_{t}\)，我们定义：

\[u_{t} \text{生成} \, p_{t} \, \text{,若对于所有} \, t \in[0,1)，有 \, X_{t}=\psi_{t}\left(X_{0}\right) \sim p_{t} \tag{3.24}\]

至此，我们在速度场、它们所定义的流以及生成的概率路径之间建立了密切的关系。需要注意的是，我们使用右开区间[0, 1)作为时间区间，这是为了处理具有紧支撑的目标分布q，在这类分布中，速度在\(t=1\)处不可以精确定义。

要验证一个速度场\(u_{t}\)是否生成某个概率路径\(p_{t}\)，可以验证\((u_{t}, p_{t})\)这对变量是否满足一个被称为**连续性方程**的偏微分方程（PDE）：
\[\frac{d}{d t} p_{t}(x)+div\left(p_{t} u_{t}\right)(x)=0 \tag{3.25}\]
其中，\(div(v)(x)=\sum_{i=1}^{d} \partial_{x^{i}} v^{i}(x)\)，且\(v(x)=(v^{1}(x), \ldots, v^{d}(x))\)。

下面的定理是质量守恒公式（Villani等人，2009）的重新表述，该定理表明，连续性方程的解\(u_{t}\)生成概率路径\(p_{t}\)：

定理2(质量守恒): 设\(p_{t}\)为一概率路径，\(u_{t}\)为局部Lipchitz可积向量场。则以下两个命题等价：
1. 连续性方程（3.25）对于\(t \in[0,1)\)成立。
2. 按照（3.24）的定义，\(u_t\)生成\(p_t\)。

以上定理中,局部利普希茨连续性假设：对于所有的\((t, x)\)，存在一个局部邻域，在该邻域内\(u_{t}(x)\)是利普希茨连续的。假设\(u_t\)是可积的，即：
\[\int_{0}^{1} \int\left\| u_{t}(x)\right\| p_{t}(x) d x d t<\infty \tag{3.26}\]

具体而言，对流动常微分方程（3.19a）的解在时间区间\([0, t]\)上进行积分，会得到如下积分方程：
\[\psi_{t}(x)=x+\int_{0}^{t} u_{s}\left(\psi_{s}(x)\right) d s \tag{3.27}\]

然后利用可积性:
\[
\begin{aligned}
\mathbb{E}\left\| X_{t}\right\| & \stackrel{(3.16)}{=} \int\left\| \psi_{t}(x)\right\| p(x) dx \\
& =\int\left\| x+\int_{0}^{t} u_{s}\left(\psi_{s}(x)\right) ds \right\| p(x) dx \\
& \stackrel{(i)}{\leq} \mathbb{E}\left\| X_{0}\right\| +\int_{0}^{1} \int\left\| u_{s}(x)\right\| p_{t}(x) dx dt \\
& \stackrel{(ii)}{<} \infty
\end{aligned}
\]

其中，(i)由三角不等式得出，(ii)假设满足可积性条件（3.26）且\(\mathbb{E}\left\|X_{0}\right\|<\infty\) 。总之，若\(X_{0}\)的期望范数有界，则可积性确保\(X_{t}\)的期望范数也有界。

为了进一步理解连续性方程的含义，我们可借助散度定理将其写成积分形式——马修斯（Matthews, 2012）对散度定理有直观阐述，卢米斯与斯特恩伯格（Loomis and Sternberg, 1968）则给出了严格论述。该定理表明，对于某个区域\(\mathcal{D}\)和某个光滑向量场\(u: \mathbb{R}^{d} \to \mathbb{R}^{d}\)，区域\(\mathcal{D}\)内部\(u\)的散度的累积量等于\(u\)通过正交穿过区域边界\(\partial \mathcal{D}\)流出\(\mathcal{D}\)的通量，即
\[
\int_{\mathcal{D}} \operatorname{div}(u)(x) d x=\int_{\partial \mathcal{D}}\langle u(y), n(y)\rangle d s_{y} \tag{3.28}
\]

为了将这些见解应用于连续性方程，我们对一个小区域\(\mathcal{D} \subset \mathbb{R}^{d}\)（例如一个立方体）积分式（3.25），并应用散度定理，得到
\[
\frac{d}{d t} \int_{\mathcal{D}} p_{t}(x) d x=-\int_{\mathcal{D}} \operatorname{div}\left(p_{t} u_{t}\right)(x) d x=-\int_{\partial \mathcal{D}}\left\langle p_{t}(y) u_{t}(y), n(y)\right\rangle d s_{y} \tag{3.29}
\]

该方程将体积\(D\)中总概率质量的变化率（左侧）表示为离开该区域的负概率通量（右侧）。概率通量定义为\(j_{t}(y)=p_{t}(y) u_{t}(y)\)，它是单位时间内通过与\(n(y)\)正交的超平面的单位（可能是高维的）面积上的概率质量。

## 3.6 瞬时变量替换
使用流作为生成模型的一个重要优势是，它们允许对所有\(x \in \mathbb{R}^{d}\)的精确似然\(\log p_{1}(x)\)进行易于处理的计算。这一特性是由名为“瞬时变量替换”的连续性方程所导致的（Chen等人，2018），即
\[
\frac{d}{d t} \log p_{t}\left(\psi_{t}(x)\right)=-\operatorname{div}\left(u_{t}\right)\left(\psi_{t}(x)\right) \tag{3.30}
\]

这是控制对数似然\(\log p_{t}(\psi_{t}(x))\)沿由式（3.19a）定义的流ODE的常微分方程。为了推导式（3.30），需要对\(\log p_{t}(\psi_{t}(x))\)关于时间求导，并同时应用连续性方程（3.25）和流ODE（3.19a）.

将式（3.30）从\(t=0\)积分到\(t=1\)并整理，我们得到
\[
\log p_{1}\left(\psi_{1}(x)\right)=\log p_{0}\left(\psi_{0}(x)\right)-\int_{0}^{1} \operatorname{div}\left(u_{t}\right)\left(\psi_{t}(x)\right) d t \tag{3.31}
\]

在实际中，计算\(div(u_{t})\)（它等于雅可比矩阵\(\partial_{x} u_{t}(x) \in \mathbb{R}^{d ×d}\)的迹）的难度会随着维度\(d\)的增加而不断加大。正因如此，先前的研究采用了无偏估计量，例如哈钦森迹估计量（Grathwohl等人，2018）：
\[div\left(u_{t}\right)(x)=tr\left[\partial_{x} u_{t}(x)\right]=\mathbb{E}_{Z} tr\left[Z^{T} \partial_{x} u_{t}(x) Z\right] \tag{3.32}\]
其中\(Z \in \mathbb{R}^{d ×d}\)是任意满足\(E[Z]=0\)且\(Cov(Z, Z)=I\)的随机变量（例如，\(Z \sim N(0, I)\)），而\(tr[Z]=\sum_{i=1}^{d} Z_{i, i}\)。将上式代入式（3.31）并交换积分与期望的顺序，可得如下无偏对数似然估计量：
\[log p_{1}\left(\psi_{1}(x)\right)=log p_{0}\left(\psi_{0}(x)\right)-\mathbb{E}_{Z} \int_{0}^{1} tr\left[Z^{T} \partial_{x} u_{t}\left(\psi_{t}(x)\right) Z\right] d t \tag{3.33}\]

与式（3.30）中的\(div(u_{t})(\psi_{t}(x))\)不同，对于上述方程中一个固定的样本\(Z\)，计算\(tr[Z^{T} \partial_{x} u_{t}(\psi_{t}(x)) Z]\)可通过一次反向传播实现，这借助了向量-雅可比积（JVP）。

总之，计算\(\log p_{1}(x)\)的无偏估计需要模拟如下常微分方程
\[\frac{d}{d t}\left[\begin{array}{c} f(t) \\ g(t) \end{array}\right]=\left[\begin{array}{c} u_{t}(f(t)) \\ -\operatorname{tr}\left[Z^{T} \partial_{x} u_{t}(f(t)) Z\right] \end{array}\right] \tag{3.34a}\]
\[\left[\begin{array}{l}f(1) \\ g(1)\end{array}\right]=\left[\begin{array}{l}x \\ 0\end{array}\right] \tag{3.34b}\]
并从时间\(t=1\)反向积分到\(t=0\)，然后令
\[\hat{\log p_{1}}(x)=\log p_{0}(f(0))-g(0) \tag{3.35}\]

## 3.7 使用模拟方法训练流模型
瞬时变量替换以及由此产生的常微分方程组（3.34），使得通过最大化训练数据的对数似然来训练流模型成为可能（Chen等人，2018；Grathwohl等人，2018）。具体而言，设\(u_{t}^{\theta}\)是一个具有可学习参数\(\theta \in \mathbb{R}^{p}\)的速度场，考虑学习参数\(\theta\)使得
\[p_{1}^{\theta} \approx q \tag{3.36}\]

例如，我们可以通过最小化\(p_{1}^{\theta}\)与\(q\)的KL散度来实现这一目标：
\[
\mathcal{L}(\theta)=D_{KL}\left(q, p_{1}^{\theta}\right)=-\mathbb{E}_{Y \sim q} \log p_{1}^{\theta}(Y)+\text { constant } \tag{3.37}
\]
其中，\(p_{1}^{\theta}\)是\(X_{1}=\psi_{1}^{\theta}(X_{0})\)的分布，\(\psi_{t}^{\theta}\)由\(u_{t}^{\theta}\)定义，并且我们可以通过求解常微分方程组（3.34）得到\(\log p_{1}^{\theta}(Y)\)的无偏估计。然而，计算这一损失及其梯度时，在训练过程中需要进行精确的常微分方程模拟，只有无误差的解才能构成无偏梯度。相比之下，接下来要介绍的流匹配（Flow Matching）是一种无需模拟的框架，训练流生成模型时不需要在训练过程中求解常微分方程。

